{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be988073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c845657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/11 15:35:57 WARN Utils: Your hostname, beast resolves to a loopback address: 127.0.1.1; using 192.168.0.125 instead (on interface wlp4s0)\n",
      "22/12/11 15:35:57 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/11 15:35:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/12/11 15:35:59 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('coba2') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdae8971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.125:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>coba2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f5b6a928760>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spark.stop()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "590c9d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "[Stage 0:===========================================================(1 + 0) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "parqDF = spark.read.parquet(\"fhv_tripdata_2021-02.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b33f88b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: double (nullable = true)\n",
      " |-- DOlocationID: double (nullable = true)\n",
      " |-- SR_Flag: integer (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimbo/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n",
      "/home/jimbo/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2021-02-01 07:01:00</td>\n",
       "      <td>2021-02-01 08:33:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00021</td>\n",
       "      <td>2021-02-01 07:55:40</td>\n",
       "      <td>2021-02-01 08:06:20</td>\n",
       "      <td>173.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00021</td>\n",
       "      <td>2021-02-01 07:14:03</td>\n",
       "      <td>2021-02-01 07:28:37</td>\n",
       "      <td>173.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00021</td>\n",
       "      <td>2021-02-01 07:27:48</td>\n",
       "      <td>2021-02-01 07:35:45</td>\n",
       "      <td>82.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-02-01 07:12:50</td>\n",
       "      <td>2021-02-01 07:26:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-02-01 07:00:37</td>\n",
       "      <td>2021-02-01 07:09:35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B00112</td>\n",
       "      <td>2021-02-01 07:30:25</td>\n",
       "      <td>2021-02-01 07:57:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B00149</td>\n",
       "      <td>2021-02-01 07:43:16</td>\n",
       "      <td>2021-02-01 08:03:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B00221</td>\n",
       "      <td>2021-02-01 07:20:45</td>\n",
       "      <td>2021-02-01 07:21:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>244.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B00225</td>\n",
       "      <td>2021-02-01 07:23:27</td>\n",
       "      <td>2021-02-01 07:55:46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num     pickup_datetime    dropOff_datetime  PUlocationID  \\\n",
       "0               B00013 2021-02-01 07:01:00 2021-02-01 08:33:00           NaN   \n",
       "1      B00021          2021-02-01 07:55:40 2021-02-01 08:06:20         173.0   \n",
       "2      B00021          2021-02-01 07:14:03 2021-02-01 07:28:37         173.0   \n",
       "3      B00021          2021-02-01 07:27:48 2021-02-01 07:35:45          82.0   \n",
       "4               B00037 2021-02-01 07:12:50 2021-02-01 07:26:38           NaN   \n",
       "5               B00037 2021-02-01 07:00:37 2021-02-01 07:09:35           NaN   \n",
       "6               B00112 2021-02-01 07:30:25 2021-02-01 07:57:23           NaN   \n",
       "7               B00149 2021-02-01 07:43:16 2021-02-01 08:03:16           NaN   \n",
       "8               B00221 2021-02-01 07:20:45 2021-02-01 07:21:15           NaN   \n",
       "9               B00225 2021-02-01 07:23:27 2021-02-01 07:55:46           NaN   \n",
       "\n",
       "   DOlocationID  SR_Flag Affiliated_base_number  \n",
       "0           NaN      NaN                 B00014  \n",
       "1          82.0      NaN        B00021           \n",
       "2          56.0      NaN        B00021           \n",
       "3         129.0      NaN        B00021           \n",
       "4         225.0      NaN                 B00037  \n",
       "5          61.0      NaN                 B00037  \n",
       "6          26.0      NaN                 B00112  \n",
       "7          72.0      NaN                 B00149  \n",
       "8         244.0      NaN                 B00221  \n",
       "9         169.0      NaN                 B00225  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data overview\n",
    "parqDF.printSchema()\n",
    "parqDF.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f32b345e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pickup_date</th>\n",
       "      <th>Trips_on_Feb15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-15</td>\n",
       "      <td>35709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Pickup_date  Trips_on_Feb15\n",
       "0  2021-02-15           35709"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. How many taxi trips were there on February 15\n",
    "\n",
    "parqDF.createOrReplaceTempView(\"Table1\")\n",
    "df = spark.sql(\"select date(pickup_datetime) as Pickup_date, count(pickup_datetime) as Trips_on_Feb15 from Table1 where pickup_datetime like '2021-02-15%' group by date(pickup_datetime)\")\n",
    "df.toPandas()\n",
    "\n",
    "# df.coalesce(1).write.format(\"test.csv\").option(\"header\", \"true\").save(\"question1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1eaf66ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.repartition(1).write.mode('default').option(\"header\", True).csv(\"question1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b830ce1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Longest_Trip_per_Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-02-06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-02-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-02-09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-02-11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-02-13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-02-14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-02-15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-02-16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-02-19</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-02-20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2021-02-21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2021-02-22</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2021-02-25</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2021-02-26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2021-02-27</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Longest_Trip_per_Day\n",
       "0   2021-02-01                    32\n",
       "1   2021-02-02                     0\n",
       "2   2021-02-03                     0\n",
       "3   2021-02-04                    27\n",
       "4   2021-02-05                    77\n",
       "5   2021-02-06                     1\n",
       "6   2021-02-07                     0\n",
       "7   2021-02-08                     6\n",
       "8   2021-02-09                     1\n",
       "9   2021-02-10                     0\n",
       "10  2021-02-11                     2\n",
       "11  2021-02-12                     3\n",
       "12  2021-02-13                     5\n",
       "13  2021-02-14                     1\n",
       "14  2021-02-15                    10\n",
       "15  2021-02-16                     3\n",
       "16  2021-02-17                     2\n",
       "17  2021-02-18                     1\n",
       "18  2021-02-19                     6\n",
       "19  2021-02-20                     1\n",
       "20  2021-02-21                     1\n",
       "21  2021-02-22                     9\n",
       "22  2021-02-23                    28\n",
       "23  2021-02-24                     1\n",
       "24  2021-02-25                    28\n",
       "25  2021-02-26                     0\n",
       "26  2021-02-27                    11\n",
       "27  2021-02-28                    10\n",
       "28  2021-03-01                     0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Find the longest trip for each day?\n",
    "\n",
    "parqDF.createOrReplaceTempView(\"Table2\")\n",
    "df = spark.sql(\"select date(pickup_datetime) as Date, max(datediff(day, pickup_datetime, dropOff_datetime)) AS Longest_Trip_per_Day from Table2 group by date(pickup_datetime) order by date(pickup_datetime) asc\")\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "248ec77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.repartition(1).write.mode('default').option(\"header\", True).csv(\"question2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14fdb351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00856</td>\n",
       "      <td>35077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B01312</td>\n",
       "      <td>33089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B01145</td>\n",
       "      <td>31114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B02794</td>\n",
       "      <td>30397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B03016</td>\n",
       "      <td>29794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num  frequency\n",
       "0               B00856      35077\n",
       "1               B01312      33089\n",
       "2               B01145      31114\n",
       "3               B02794      30397\n",
       "4               B03016      29794"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Find top 5 Most Frequent 'dispatching_base_num'\n",
    "\n",
    "parqDF.createOrReplaceTempView(\"Table3\")\n",
    "df = spark.sql(\"select dispatching_base_num, count(dispatching_base_num) as frequency from Table3 group by dispatching_base_num order by frequency desc limit 5\")\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7faa8b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.repartition(1).write.mode('default').option(\"header\", True).csv(\"question3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13136a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pulocationid</th>\n",
       "      <th>dolocationid</th>\n",
       "      <th>freq_together</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>2112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>206.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pulocationid  dolocationid  freq_together\n",
       "0         221.0         206.0           2112\n",
       "1         206.0         221.0           1309\n",
       "2         221.0         115.0           1010\n",
       "3         115.0         221.0            793\n",
       "4         115.0         206.0            769"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Find top 5 Most common location pairs (PUlocationID, DOlocationID)\n",
    "\n",
    "parqDF.createOrReplaceTempView(\"Table4\")\n",
    "df = spark.sql(\"select pulocationid, dolocationid, count(concat(PUlocationID, DOlocationID)) as freq_together from Table4 where not(pulocationid = dolocationid) group by pulocationid, dolocationid order by freq_together desc limit 5\")\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a3b6fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.repartition(1).write.mode('default').option(\"header\", True).csv(\"question4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90404944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f55a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=r\"/home/jimbo/.google/credentials/google_credentials.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd8366ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()\n",
    "table_id = \"suryo-df8.practice_case_6.question4\"\n",
    "file_path = r\"homework_csv_outputs/question4.csv\"\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    source_format = bigquery.SourceFormat.CSV, skip_leading_rows = 1, autodetect=True,\n",
    "        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    ")\n",
    "\n",
    "with open(file_path, \"rb\") as source_file:\n",
    "    job = client.load_table_from_file(source_file, table_id, job_config=job_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed2e57e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 rows and 3 columns to suryo-df8.practice_case_6.question4\n"
     ]
    }
   ],
   "source": [
    "table = client.get_table(table_id)\n",
    "print(\n",
    "    \"Loaded {} rows and {} columns to {}\".format(table.num_rows, len(table.schema), table_id)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
